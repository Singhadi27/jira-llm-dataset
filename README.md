# ğŸ§  Apache Jira â†’ JSONL Dataset Pipeline

This project scrapes public **Apache Jira issues** (e.g., Kafka, Hadoop, Spark, HBase) and converts them into a structured **JSONL dataset** suitable for **Large Language Model (LLM) training**.

It provides an end-to-end data pipeline â€” from scraping raw issues to producing preprocessed, clean JSONL and CSV datasets.

---

## ğŸš€ Features
- Scrapes public Jira issues from Apache projects  
- Cleans and structures issue data (title, description, comments, etc.)  
- Converts data into LLM-friendly JSONL format  
- Includes preprocessing and transformation utilities  
- Ready-to-train datasets for NLP/LLM use cases  

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Create Virtual Environment & Install Dependencies
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ•¸ï¸ Step 1: Scrape Apache Jira Issues
Run the scraper for one or more projects:
```bash
python scraper/scraper_api.py --project KAFKA
```
You can replace `KAFKA` with any Apache project (e.g., `HDFS`, `SPARK`, `HBASE`, etc.)

**Output:**
```
scraper/sample_output/<PROJECT>_raw.jsonl
```

---

## ğŸ§© Step 2: Transform Raw Data into Structured Format
Convert raw JSONL into structured JSONL with summaries and QA pairs:
```bash
python scraper/transform_to_jsonl.py --project KAFKA
```

**Output:**
```
scraper/sample_output/KAFKA_processed.jsonl
```

---

## ğŸ§¼ Step 3: Preprocess and Clean Data
Clean and format the transformed data for LLM use:
```bash
python preprocess.py --input scraper/sample_output/KAFKA_processed.jsonl --output data/KAFKA_preprocessed.jsonl
```

**Output:**
```
data/KAFKA_preprocessed.jsonl  
data/KAFKA_preprocessed.csv
```

âœ… This step generates the final dataset ready for analysis or LLM fine-tuning.

---

## ğŸ§ª (Optional) Step 4: Run Full Demo Pipeline
You can run the complete demo script which executes scraping and transformation automatically:
```bash
bash run_demo.sh
```

---

## ğŸ“ Project Structure
```
jira-llm-dataset/
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ scraper_api.py
â”‚   â”œâ”€â”€ transform_to_jsonl.py
â”‚   â””â”€â”€ sample_output/
â”‚       â”œâ”€â”€ KAFKA_raw.jsonl
â”‚       â”œâ”€â”€ KAFKA_processed.jsonl
â”‚       â””â”€â”€ ...
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ KAFKA_preprocessed.jsonl
â”‚   â””â”€â”€ KAFKA_preprocessed.csv
â”œâ”€â”€ preprocess.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_demo.sh
â””â”€â”€ README.md
```

---

## ğŸ§¾ Example Output (Snippet)
```json
{
  "id": "KAFKA-10006",
  "title": "Streams should not attempt to create internal topics that may exist",
  "status": "Resolved",
  "priority": "Major",
  "reporter": "A. Sophie Blee-Goldman",
  "description": "During assignment, Streams will attempt to validate all internal topics and their number of partitions...",
  "derived_summary": "During assignment, Streams will attempt to validate all internal topics and their number of partitions.",
  "derived_qas": [
    {
      "q": "What is the main issue?",
      "a": "Streams will attempt to create internal topics that already exist"
    }
  ]
}
```

---

## ğŸ§  Use Case
The resulting dataset can be used for:
- Fine-tuning LLMs for **issue summarization**
- **Bug report classification** or **QA generation**
- Building **developer assistants** for open-source projects

---

## ğŸ› ï¸ Tools & Technologies Used
- **Python** â€“ Core scripting and automation  
- **Requests / BeautifulSoup** â€“ Data scraping  
- **Pandas** â€“ Data cleaning and processing  
- **JSON / CSV** â€“ Dataset formats  
- **Virtualenv** â€“ Environment isolation  
- **Bash** â€“ Automation script (`run_demo.sh`)  

---

## ğŸ¯ Learning Outcomes
- Learned how to scrape real-world software issue data from APIs  
- Understood data cleaning and preprocessing for NLP tasks  
- Gained hands-on experience in building an automated data pipeline  
- Prepared datasets suitable for machine learning model fine-tuning  

---

## ğŸ³ Docker Setup for Jira LLM Dataset

### ğŸ§© Pull the Prebuilt Docker Image
docker pull adityasinghio/jira-llm-dataset

### ğŸš€ Step 1: Run the Project Inside the Container
docker run -it adityasinghio/jira-llm-dataset

### ğŸ’¾ (Optional) Step 2: Persist Output Files to Your Local Machine
This mounts your local "outputs" folder to the containerâ€™s /app/sample_output directory.
docker run -it -v $(pwd)/outputs:/app/sample_output adityasinghio/jira-llm-dataset

### ğŸ“‚ Step 3: Check the Saved Outputs Locally
ls outputs/

### ğŸ—ï¸ (For Developers) Step 4: Build the Docker Image Yourself
docker build -t jira-llm-dataset .

---

## ğŸ‘¤ Author
**Aditya Singh**  
Final Year B.Tech CSE Student | DevOps & Cloud Enthusiast  

ğŸ”— **Docker Hub:** [adityasingh1404/jira-llm-dataset](https://hub.docker.com/r/adityasinghio/jira-llm-datasett)

